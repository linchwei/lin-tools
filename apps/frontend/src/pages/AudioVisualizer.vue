<template>
  <div class="audio-visualizer-container min-h-screen bg-gradient-to-br from-gray-900 via-purple-900 to-indigo-900 p-6">
    <div class="max-w-6xl mx-auto">
      <!-- æ ‡é¢˜ -->
      <div class="text-center mb-8">
        <h1 class="text-4xl font-bold text-white mb-2">ğŸµ éŸ³é¢‘å¯è§†åŒ–åˆ†æå™¨</h1>
        <p class="text-gray-300">ä½¿ç”¨Web Audio APIå®ç°å®æ—¶éŸ³é¢‘åˆ†æå’Œå¯è§†åŒ–</p>
      </div>

      <!-- æ§åˆ¶é¢æ¿ -->
      <div class="control-panel bg-black/30 backdrop-blur-xl rounded-2xl p-6 mb-6 border border-white/10">
        <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
          <!-- éŸ³é¢‘æºé€‰æ‹© -->
          <div class="audio-source">
            <h3 class="text-white font-semibold mb-3">éŸ³é¢‘æº</h3>
            <div class="space-y-3">
              <el-button @click="initializeMicrophone" :disabled="!canUseMicrophone" type="primary" class="w-full">
                <el-icon>
                  <Microphone />
                </el-icon>
                ä½¿ç”¨éº¦å…‹é£
              </el-button>

              <div class="file-upload">
                <input ref="fileInput" type="file" accept="audio/*" @change="handleFileUpload" class="hidden">
                <el-button @click="fileInput?.click()" class="w-full">
                  <el-icon>
                    <Upload />
                  </el-icon>
                  ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
                </el-button>
              </div>

              <audio ref="audioElement" controls class="w-full" @play="startVisualization" @pause="stopVisualization"
                @ended="stopVisualization" />
            </div>
          </div>

          <!-- å¯è§†åŒ–è®¾ç½® -->
          <div class="visualization-settings">
            <h3 class="text-white font-semibold mb-3">å¯è§†åŒ–æ¨¡å¼</h3>
            <el-select v-model="visualizationMode" class="w-full mb-3">
              <el-option label="é¢‘è°±æ¡å½¢å›¾" value="bars" />
              <el-option label="åœ†å½¢é¢‘è°±" value="circular" />
              <el-option label="æ³¢å½¢å›¾" value="waveform" />
              <el-option label="ç²’å­æ•ˆæœ" value="particles" />
              <el-option label="3Dé¢‘è°±" value="3d" />
            </el-select>

            <div class="settings-grid grid grid-cols-2 gap-2">
              <div>
                <label class="text-xs text-gray-300">FFTå¤§å°</label>
                <el-select v-model="fftSize" size="small">
                  <el-option label="512" :value="512" />
                  <el-option label="1024" :value="1024" />
                  <el-option label="2048" :value="2048" />
                  <el-option label="4096" :value="4096" />
                </el-select>
              </div>
              <div>
                <label class="text-xs text-gray-300">å¹³æ»‘åº¦</label>
                <el-slider v-model="smoothing" :min="0" :max="1" :step="0.1" size="small" />
              </div>
            </div>
          </div>

          <!-- éŸ³é¢‘ä¿¡æ¯ -->
          <div class="audio-info">
            <h3 class="text-white font-semibold mb-3">éŸ³é¢‘ä¿¡æ¯</h3>
            <div class="info-grid space-y-2 text-sm">
              <div class="flex justify-between text-gray-300">
                <span>å¹³å‡é¢‘ç‡:</span>
                <span class="text-green-400">{{ averageFrequency.toFixed(1) }}</span>
              </div>
              <div class="flex justify-between text-gray-300">
                <span>ä½é¢‘å¼ºåº¦:</span>
                <span class="text-blue-400">{{ bassLevel.toFixed(1) }}</span>
              </div>
              <div class="flex justify-between text-gray-300">
                <span>é«˜é¢‘å¼ºåº¦:</span>
                <span class="text-purple-400">{{ trebleLevel.toFixed(1) }}</span>
              </div>
              <div class="flex justify-between text-gray-300">
                <span>çŠ¶æ€:</span>
                <el-tag :type="isAnalyzing ? 'success' : 'info'" size="small">
                  {{ isAnalyzing ? 'åˆ†æä¸­' : 'å·²åœæ­¢' }}
                </el-tag>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- å¯è§†åŒ–ç”»å¸ƒ -->
      <div class="visualization-area bg-black/20 backdrop-blur-xl rounded-2xl p-6 border border-white/10">
        <canvas ref="visualizerCanvas" class="w-full rounded-lg shadow-2xl" :class="{ 'animate-pulse': isAnalyzing }" />
      </div>

      <!-- é¢‘ç‡åˆ†æé¢æ¿ -->
      <div class="frequency-analysis mt-6 bg-black/30 backdrop-blur-xl rounded-2xl p-6 border border-white/10">
        <h3 class="text-white font-semibold mb-4">é¢‘ç‡åˆ†æ</h3>
        <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
          <!-- é¢‘ç‡åˆ†å¸ƒå›¾ -->
          <div class="frequency-chart">
            <h4 class="text-gray-300 text-sm mb-2">é¢‘ç‡åˆ†å¸ƒ</h4>
            <canvas ref="frequencyChart" width="300" height="150" class="w-full border border-gray-600 rounded" />
          </div>

          <!-- å®æ—¶æ³¢å½¢ -->
          <div class="waveform-chart">
            <h4 class="text-gray-300 text-sm mb-2">å®æ—¶æ³¢å½¢</h4>
            <canvas ref="waveformChart" width="300" height="150" class="w-full border border-gray-600 rounded" />
          </div>

          <!-- é¢‘è°±ç€‘å¸ƒå›¾ -->
          <div class="spectrogram">
            <h4 class="text-gray-300 text-sm mb-2">é¢‘è°±å†å²</h4>
            <canvas ref="spectrogramChart" width="300" height="150" class="w-full border border-gray-600 rounded" />
          </div>
        </div>
      </div>

      <!-- é¢„è®¾æ•ˆæœ -->
      <div class="presets mt-6 bg-black/30 backdrop-blur-xl rounded-2xl p-6 border border-white/10">
        <h3 class="text-white font-semibold mb-4">é¢„è®¾æ•ˆæœ</h3>
        <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
          <el-button v-for="preset in presets" :key="preset.name" @click="applyPreset(preset)"
            :type="currentPreset === preset.name ? 'primary' : 'default'" class="preset-button">
            {{ preset.name }}
          </el-button>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { Microphone, Upload } from '@element-plus/icons-vue'
import { AudioAnalyzer } from '@/utils/audioAnalyzer'
import { AudioVisualizer, Particle } from '@/utils/audioVisualizer'

// å“åº”å¼æ•°æ®
const visualizerCanvas = ref<HTMLCanvasElement>()
const frequencyChart = ref<HTMLCanvasElement>()
const waveformChart = ref<HTMLCanvasElement>()
const spectrogramChart = ref<HTMLCanvasElement>()
const audioElement = ref<HTMLAudioElement>()
const fileInput = ref<HTMLInputElement>()

const visualizationMode = ref<'bars' | 'circular' | 'waveform' | 'particles' | '3d'>('bars')
const fftSize = ref(2048)
const smoothing = ref(0.8)
const isAnalyzing = ref(false)
const canUseMicrophone = ref(true)
const currentPreset = ref('')

// éŸ³é¢‘æ•°æ®
const averageFrequency = ref(0)
const bassLevel = ref(0)
const trebleLevel = ref(0)

// å®ä¾‹
let audioAnalyzer: AudioAnalyzer | null = null
let visualizer: AudioVisualizer | null = null
let particles: Particle[] = []
let spectrogramData: number[][] = []

// é¢„è®¾é…ç½®
const presets = [
  {
    name: 'ç»å…¸',
    mode: 'bars' as const,
    fftSize: 2048,
    smoothing: 0.8
  },
  {
    name: 'åŠ¨æ„Ÿ',
    mode: 'circular' as const,
    fftSize: 1024,
    smoothing: 0.6
  },
  {
    name: 'ç§‘å¹»',
    mode: 'particles' as const,
    fftSize: 4096,
    smoothing: 0.9
  },
  {
    name: 'ç«‹ä½“',
    mode: '3d' as const,
    fftSize: 1024,
    smoothing: 0.7
  }
]

onMounted(async () => {
  await initializeVisualizer()
  checkMicrophonePermission()
})

const initializeVisualizer = async () => {
  if (!visualizerCanvas.value) return

  try {
    audioAnalyzer = new AudioAnalyzer({
      fftSize: fftSize.value,
      smoothingTimeConstant: smoothing.value
    })

    await audioAnalyzer.initialize()

    visualizer = new AudioVisualizer(visualizerCanvas.value, {
      width: 800,
      height: 400
    })

    // åˆå§‹åŒ–ç²’å­
    initializeParticles()

    ElMessage.success('éŸ³é¢‘åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ')
  } catch (error) {
    ElMessage.error('åˆå§‹åŒ–å¤±è´¥: ' + (error as Error).message)
  }
}

const initializeParticles = () => {
  particles = []
  for (let i = 0; i < 100; i++) {
    particles.push(new Particle(
      Math.random() * 800,
      Math.random() * 400
    ))
  }
}

const checkMicrophonePermission = async () => {
  try {
    await navigator.mediaDevices.getUserMedia({ audio: true })
    canUseMicrophone.value = true
  } catch {
    canUseMicrophone.value = false
  }
}

const initializeMicrophone = async () => {
  if (!audioAnalyzer) return

  try {
    await audioAnalyzer.connectMicrophone()
    await audioAnalyzer.resume()
    startVisualization()
    ElMessage.success('éº¦å…‹é£è¿æ¥æˆåŠŸ')
  } catch (error) {
    ElMessage.error('éº¦å…‹é£è¿æ¥å¤±è´¥: ' + (error as Error).message)
  }
}

const handleFileUpload = (event: Event) => {
  const file = (event.target as HTMLInputElement).files?.[0]
  if (!file || !audioElement.value) return

  const url = URL.createObjectURL(file)
  audioElement.value.src = url

  if (audioAnalyzer) {
    audioAnalyzer.connectAudioElement(audioElement.value)
  }
}

const startVisualization = async () => {
  if (!audioAnalyzer || !visualizer) return

  try {
    await audioAnalyzer.resume()
    isAnalyzing.value = true

    audioAnalyzer.startAnalysis((data) => {
      averageFrequency.value = data.averageFrequency
      bassLevel.value = data.bassLevel
      trebleLevel.value = data.trebleLevel

      // ä¸»å¯è§†åŒ–
      switch (visualizationMode.value) {
        case 'bars':
          visualizer!.renderBars(data.frequencyData)
          break
        case 'circular':
          visualizer!.renderCircular(data.frequencyData)
          break
        case 'waveform':
          visualizer!.renderWaveform(data.timeDomainData)
          break
        case 'particles':
          visualizer!.renderParticles(data.frequencyData, particles)
          break
        case '3d':
          visualizer!.render3DSpectrum(data.frequencyData)
          break
      }

      // æ›´æ–°åˆ†æå›¾è¡¨
      updateAnalysisCharts(data)
    })
  } catch (error) {
    ElMessage.error('å¯åŠ¨å¯è§†åŒ–å¤±è´¥: ' + (error as Error).message)
  }
}

const stopVisualization = () => {
  if (audioAnalyzer) {
    audioAnalyzer.stopAnalysis()
  }
  isAnalyzing.value = false
}

const updateAnalysisCharts = (data: any) => {
  // æ›´æ–°é¢‘ç‡åˆ†å¸ƒå›¾
  if (frequencyChart.value) {
    const ctx = frequencyChart.value.getContext('2d')!
    ctx.fillStyle = '#1a1a2e'
    ctx.fillRect(0, 0, 300, 150)

    const barWidth = 300 / data.frequencyData.length
    for (let i = 0; i < data.frequencyData.length; i++) {
      const barHeight = (data.frequencyData[i] / 255) * 150
      ctx.fillStyle = `hsl(${(i / data.frequencyData.length) * 360}, 70%, 60%)`
      ctx.fillRect(i * barWidth, 150 - barHeight, barWidth, barHeight)
    }
  }

  // æ›´æ–°æ³¢å½¢å›¾
  if (waveformChart.value) {
    const ctx = waveformChart.value.getContext('2d')!
    ctx.fillStyle = '#1a1a2e'
    ctx.fillRect(0, 0, 300, 150)

    ctx.strokeStyle = '#4ecdc4'
    ctx.lineWidth = 2
    ctx.beginPath()

    const sliceWidth = 300 / data.timeDomainData.length
    let x = 0

    for (let i = 0; i < data.timeDomainData.length; i++) {
      const v = data.timeDomainData[i] / 128.0
      const y = v * 75

      if (i === 0) {
        ctx.moveTo(x, y)
      } else {
        ctx.lineTo(x, y)
      }

      x += sliceWidth
    }

    ctx.stroke()
  }

  // æ›´æ–°é¢‘è°±ç€‘å¸ƒå›¾
  updateSpectrogram(data.frequencyData)
}

const updateSpectrogram = (frequencyData: Uint8Array) => {
  if (!spectrogramChart.value) return

  // æ·»åŠ æ–°çš„é¢‘è°±æ•°æ®
  spectrogramData.push(Array.from(frequencyData))

  // é™åˆ¶å†å²æ•°æ®é•¿åº¦
  if (spectrogramData.length > 150) {
    spectrogramData.shift()
  }

  const ctx = spectrogramChart.value.getContext('2d')!
  ctx.fillStyle = '#1a1a2e'
  ctx.fillRect(0, 0, 300, 150)

  const imageData = ctx.createImageData(300, 150)

  for (let y = 0; y < spectrogramData.length; y++) {
    const spectrum = spectrogramData[y]
    for (let x = 0; x < Math.min(spectrum.length, 300); x++) {
      const intensity = spectrum[x] / 255
      const pixelIndex = (y * 300 + x) * 4

      // æ ¹æ®å¼ºåº¦è®¾ç½®é¢œè‰²
      imageData.data[pixelIndex] = intensity * 255     // R
      imageData.data[pixelIndex + 1] = intensity * 100 // G
      imageData.data[pixelIndex + 2] = intensity * 200 // B
      imageData.data[pixelIndex + 3] = 255             // A
    }
  }

  ctx.putImageData(imageData, 0, 0)
}

const applyPreset = (preset: any) => {
  visualizationMode.value = preset.mode
  fftSize.value = preset.fftSize
  smoothing.value = preset.smoothing
  currentPreset.value = preset.name

  // é‡æ–°åˆå§‹åŒ–åˆ†æå™¨
  if (audioAnalyzer) {
    audioAnalyzer.destroy()
    nextTick(() => {
      initializeVisualizer()
    })
  }
}

// ç›‘å¬è®¾ç½®å˜åŒ–
watch([fftSize, smoothing], () => {
  if (audioAnalyzer) {
    audioAnalyzer.destroy()
    nextTick(() => {
      initializeVisualizer()
    })
  }
})

onBeforeUnmount(() => {
  if (audioAnalyzer) {
    audioAnalyzer.destroy()
  }
})
</script>

<style scoped>
.preset-button {
  transition: all 0.3s ease;
}

.preset-button:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
}

canvas {
  background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
}

.animate-pulse {
  animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

@keyframes pulse {

  0%,
  100% {
    opacity: 1;
  }

  50% {
    opacity: .8;
  }
}
</style>